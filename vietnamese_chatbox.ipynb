{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vfast/Documents/VFAST/healthy_chatbot/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vfast/Documents/VFAST/healthy_chatbot/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to new file\n",
    "datafile = (\"./data/data_converted.txt\")\n",
    "delimiter = '~'\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "corpus_name = \"data\"\n",
    "MAX_LENGTH = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 1295 sentence pairs\n",
      "Trimmed to 1294 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 6260\n",
      "\n",
      "pairs:\n",
      "['\" hở van tim hai lá 1,54 có nguy_hiểm không \"', '\" hở van 14 là hở van nhẹ , hở van 1,54 là mức_độ nhẹ đến vừa . thông_thường thì các van tim có_thể không hở hoặc hở mức_độ nhẹ ( kèm theo mô_tả cấu_trúc van không có gì bất_thường , ví_dụ như van không dày , không vôi_hóa , không sa lá van , ... ) và mức_độ hở nhẹ như vậy hầu_như không ảnh_hưởng gì đến chức_năng tim và không gây ra triệu_chứng gì . tuy_nhiên , mọi người nên tránh các chất kích_thích ( rượu_bia , trà , cafe , thuốc_lá , thuốc_lào , ... ) vì sẽ làm cho tim đập nhanh ; tránh các gắng_sức quá nặng , cũng sẽ làm tim đập nhanh và có_thể làm mức_độ hở van sẽ nặng lên . người_bệnh nên đi khám sức_khỏe định_kỳ 6 - 12 tháng lần để được kiểm_tra về sức_khỏe và có_thể làm siêu_âm tim để theo_dõi định_kì ( 1 - 3 năm lần ) . với những mức_độ hở van nhiều hơn , như của chồng bạn là hở van hai lá 1,54 thì thường cũng không cần phải điều_trị thuốc nếu như_không có các bệnh_lý tim khác kèm theo . chồng bạn cũng cần tránh các chất kích_thích như trên , cũng như là tái khám định_kỳ để theo_dõi sự tiến_triển của bệnh . \"']\n",
      "['\" khắc_phục tim đập nhanh khi thay_đổi tư_thế như thế_nào \"', '\" theo như triệu_chứng bạn mô_tả , nếu tình_trạng hồi_hộp trống_ngực , tim đập nhanh diễn ra trong thời_gian dài hoặc tần_suất xuất_hiện nhiều , bạn cần đi khám để loại_trừ các bệnh_lý rối_loạn nhịp tim nguy_hiểm . \"']\n",
      "['\" khó thở kèm thở gấp có phải triệu_chứng_bệnh tim không ? \"', '\" theo như triệu_chứng bạn mô_tả , biểu_hiện này chưa thể kết_luận là bị bệnh tim_mạch . tuy_nhiên , nếu các triệu_chứng còn tái_diễn nhiều lần , bạn cần đi khám chuyên_khoa để loại_trừ các bệnh_lý tim_mạch . \"']\n",
      "['\" đột_nhiên đau tức ngực có sao không ? \"', '\" đau vùng ngực có nhiều nguyên_nhân : lo_âu , bệnh thần_kinh liên sườn , bệnh tim_mạch , bệnh phổi màng phổi ... vì_vậy , bạn nên đến bệnh_viện khám chuyên_khoa_nội tim_mạch sớm . \"']\n",
      "['\" vinmec có holter điện tâm_đồ chẩn_đoán nguyên_nhân tim đập nhanh không ? \"', '\" triệu_chứng của bạn khó_chịu vùng ngực , tim nhanh ... nhưng đã làm điện_tim , siêu_âm tim kết_quả bình_thường . bác_sĩ có_thể nghĩ đến hội_chứng rối_loạn thần_kinh thực_vật ( thể tăng hoạt_tính_giao_cảm ) . \"']\n",
      "['\" thông liên thất kích_thước 0.6 mm nguy_hiểm không ? \"', '\" thông liên thất là một bệnh_lý tim bẩm_sinh , có sự hình_thành 1 lỗ giữa hai buồng tâm_thất . trường_hợp của bạn có thông liên thất lỗ 0.6 mm là rất nhỏ , không cần phải xử_trí gì thêm . \"']\n",
      "['\" người mắc kawasemi có giãn mạch vành 2.5 mm nguy_hiểm không ? \"', '\" hiện_tại , mức_độ giãn động_mạch_vành của bạn là không nhiều , tuy_nhiên khó có khả_năng mạch vành có_thể co lại bình_thường . bạn nên đến khám tại các bệnh_viện có chuyên_khoa tim_mạch để được tư_vấn và theo_dõi điều_trị thích_hợp . \"']\n",
      "['\" người_bệnh có tiền_sử bệnh tim_mạch đột_ngột bị ngất là do đâu ? \"', '\" đối_với tất_cả các trường_hợp bị ngất đều cần đến khám bác_sĩ tim_mạch để được tư_vấn và tầm soát nguyên_nhân gây ngất của bệnh_nhân . khi đến khám , bệnh_nhân sẽ được cho làm các xét_nghiệm như : điện tâm_đồ thường , holter điện tâm_đồ , siêu_âm tim , siêu_âm doppler động_mạch cảnh , ct mri não , và một_số xét_nghiệm máu cần_thiết khác để tầm soát nguyên_nhân . \"']\n",
      "['\" đau nhức chân tay khi sốt siêu_vi nên làm gì ? \"', '\" bạn cần đến bệnh_viện để bác_sĩ thăm khám và làm xét_nghiệm để chẩn_đoán bệnh cho bạn . nếu khi khỏi sốt virus mà tình_trạng đau nhức ống_chân của bạn còn tồn_tại thì lúc đó bạn cần thăm khám chuyên_khoa cơ xương khớp . trong thời_gian sốt virus bạn cần nghỉ_ngơi và dinh_dưỡng tốt để nhanh hồi_phục_sức_khỏe tránh vận_động thể_dục mạnh . \"']\n",
      "['\" khắc_phục ngủ mơ thường_xuyên như thế_nào ? \"', '\" ngủ hay nằm_mơ là dấu_hiệu của thiểu_năng tuần_hoàn não , bạn cần đi khám bác_sĩ nội thần_kinh để được thăm khám và điều_trị . ngoài_ra , bạn cần tập_thể_dục nhiều , uống nhiều nước , ăn nhiều rau xanh , trái_cây , tránh thức khuya nhiều . \"']\n"
     ]
    }
   ],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = ViTokenizer.tokenize(u\"{}\".format(s))\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "\n",
    "\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('~')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name, datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "print(corpus_name)\n",
    "voc, pairs = loadPrepareData(corpus_name, datafile)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 6257 / 6257 = 1.0000\n",
      "Trimmed from 1294 pairs to 1294, 1.0000 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 1    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[   3,    3,    3,    3,    3],\n",
      "        [  86, 2503,  550,   62,  604],\n",
      "        [   6,  451,  140,  117,  360],\n",
      "        [  14,   16,  430,   82,  182],\n",
      "        [  31,  594,  214,  640,  605],\n",
      "        [  16,  711, 1839,  800,   10],\n",
      "        [ 655, 2503,   24,   63,  149],\n",
      "        [1322,   22,  989, 1012,   12],\n",
      "        [  23, 1105,   12, 1970,  134],\n",
      "        [ 106,  283,  134,  134,    3],\n",
      "        [ 141, 1354,    3,    3,    2],\n",
      "        [ 533,  134,    2,    2,    0],\n",
      "        [ 134,    3,    0,    0,    0],\n",
      "        [   3,    2,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths: tensor([15, 14, 12, 12, 11])\n",
      "target_variable: tensor([[   3,    3,    3,    3,    3],\n",
      "        [  86, 1105,  104,   63,  108],\n",
      "        [   6,  323,   98, 1012,   86],\n",
      "        ...,\n",
      "        [   0,    0,    0,   20,    0],\n",
      "        [   0,    0,    0,    3,    0],\n",
      "        [   0,    0,    0,    2,    0]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  True, False],\n",
      "        [False, False, False,  True, False],\n",
      "        [False, False, False,  True, False]])\n",
      "max_target_len: 291\n"
     ]
    }
   ],
   "source": [
    "# Get index from sentence\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "# Add zero token\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "# Convert binary matrix  \n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.index2word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    # Lengths for rnn packing should always be on the cpu\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n",
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 50; Percent complete: 0.8%; Average loss: 6.9004\n",
      "Iteration: 100; Percent complete: 1.7%; Average loss: 6.4650\n",
      "Iteration: 150; Percent complete: 2.5%; Average loss: 6.2206\n",
      "Iteration: 200; Percent complete: 3.3%; Average loss: 5.8960\n",
      "Iteration: 250; Percent complete: 4.2%; Average loss: 5.5477\n",
      "Iteration: 300; Percent complete: 5.0%; Average loss: 5.2362\n",
      "Iteration: 350; Percent complete: 5.8%; Average loss: 4.9895\n",
      "Iteration: 400; Percent complete: 6.7%; Average loss: 4.7386\n",
      "Iteration: 450; Percent complete: 7.5%; Average loss: 4.5264\n",
      "Iteration: 500; Percent complete: 8.3%; Average loss: 4.3366\n",
      "Iteration: 550; Percent complete: 9.2%; Average loss: 4.1547\n",
      "Iteration: 600; Percent complete: 10.0%; Average loss: 3.9891\n",
      "Iteration: 650; Percent complete: 10.8%; Average loss: 3.8257\n",
      "Iteration: 700; Percent complete: 11.7%; Average loss: 3.6509\n",
      "Iteration: 750; Percent complete: 12.5%; Average loss: 3.4579\n",
      "Iteration: 800; Percent complete: 13.3%; Average loss: 3.3262\n",
      "Iteration: 850; Percent complete: 14.2%; Average loss: 3.1860\n",
      "Iteration: 900; Percent complete: 15.0%; Average loss: 3.0409\n",
      "Iteration: 950; Percent complete: 15.8%; Average loss: 2.8788\n",
      "Iteration: 1000; Percent complete: 16.7%; Average loss: 2.7792\n",
      "Iteration: 1050; Percent complete: 17.5%; Average loss: 2.6498\n",
      "Iteration: 1100; Percent complete: 18.3%; Average loss: 2.4901\n",
      "Iteration: 1150; Percent complete: 19.2%; Average loss: 2.4139\n",
      "Iteration: 1200; Percent complete: 20.0%; Average loss: 2.2941\n",
      "Iteration: 1250; Percent complete: 20.8%; Average loss: 2.1743\n",
      "Iteration: 1300; Percent complete: 21.7%; Average loss: 2.0516\n",
      "Iteration: 1350; Percent complete: 22.5%; Average loss: 1.9502\n",
      "Iteration: 1400; Percent complete: 23.3%; Average loss: 1.8595\n",
      "Iteration: 1450; Percent complete: 24.2%; Average loss: 1.7560\n",
      "Iteration: 1500; Percent complete: 25.0%; Average loss: 1.6465\n",
      "Iteration: 1550; Percent complete: 25.8%; Average loss: 1.5802\n",
      "Iteration: 1600; Percent complete: 26.7%; Average loss: 1.4925\n",
      "Iteration: 1650; Percent complete: 27.5%; Average loss: 1.4099\n",
      "Iteration: 1700; Percent complete: 28.3%; Average loss: 1.3305\n",
      "Iteration: 1750; Percent complete: 29.2%; Average loss: 1.2572\n",
      "Iteration: 1800; Percent complete: 30.0%; Average loss: 1.1951\n",
      "Iteration: 1850; Percent complete: 30.8%; Average loss: 1.1224\n",
      "Iteration: 1900; Percent complete: 31.7%; Average loss: 1.0644\n",
      "Iteration: 1950; Percent complete: 32.5%; Average loss: 1.0136\n",
      "Iteration: 2000; Percent complete: 33.3%; Average loss: 0.9578\n",
      "Iteration: 2050; Percent complete: 34.2%; Average loss: 0.9002\n",
      "Iteration: 2100; Percent complete: 35.0%; Average loss: 0.8459\n",
      "Iteration: 2150; Percent complete: 35.8%; Average loss: 0.7877\n",
      "Iteration: 2200; Percent complete: 36.7%; Average loss: 0.7439\n",
      "Iteration: 2250; Percent complete: 37.5%; Average loss: 0.6996\n",
      "Iteration: 2300; Percent complete: 38.3%; Average loss: 0.6654\n",
      "Iteration: 2350; Percent complete: 39.2%; Average loss: 0.6048\n",
      "Iteration: 2400; Percent complete: 40.0%; Average loss: 0.5674\n",
      "Iteration: 2450; Percent complete: 40.8%; Average loss: 0.5399\n",
      "Iteration: 2500; Percent complete: 41.7%; Average loss: 0.5092\n",
      "Iteration: 2550; Percent complete: 42.5%; Average loss: 0.4743\n",
      "Iteration: 2600; Percent complete: 43.3%; Average loss: 0.4420\n",
      "Iteration: 2650; Percent complete: 44.2%; Average loss: 0.4251\n",
      "Iteration: 2700; Percent complete: 45.0%; Average loss: 0.3938\n",
      "Iteration: 2750; Percent complete: 45.8%; Average loss: 0.3693\n",
      "Iteration: 2800; Percent complete: 46.7%; Average loss: 0.3504\n",
      "Iteration: 2850; Percent complete: 47.5%; Average loss: 0.3275\n",
      "Iteration: 2900; Percent complete: 48.3%; Average loss: 0.3070\n",
      "Iteration: 2950; Percent complete: 49.2%; Average loss: 0.2860\n",
      "Iteration: 3000; Percent complete: 50.0%; Average loss: 0.2755\n",
      "Iteration: 3050; Percent complete: 50.8%; Average loss: 0.2578\n",
      "Iteration: 3100; Percent complete: 51.7%; Average loss: 0.2454\n",
      "Iteration: 3150; Percent complete: 52.5%; Average loss: 0.2318\n",
      "Iteration: 3200; Percent complete: 53.3%; Average loss: 0.2207\n",
      "Iteration: 3250; Percent complete: 54.2%; Average loss: 0.2106\n",
      "Iteration: 3300; Percent complete: 55.0%; Average loss: 0.2002\n",
      "Iteration: 3350; Percent complete: 55.8%; Average loss: 0.1876\n",
      "Iteration: 3400; Percent complete: 56.7%; Average loss: 0.1803\n",
      "Iteration: 3450; Percent complete: 57.5%; Average loss: 0.1713\n",
      "Iteration: 3500; Percent complete: 58.3%; Average loss: 0.1615\n",
      "Iteration: 3550; Percent complete: 59.2%; Average loss: 0.1551\n",
      "Iteration: 3600; Percent complete: 60.0%; Average loss: 0.1510\n",
      "Iteration: 3650; Percent complete: 60.8%; Average loss: 0.1432\n",
      "Iteration: 3700; Percent complete: 61.7%; Average loss: 0.1374\n",
      "Iteration: 3750; Percent complete: 62.5%; Average loss: 0.1309\n",
      "Iteration: 3800; Percent complete: 63.3%; Average loss: 0.1229\n",
      "Iteration: 3850; Percent complete: 64.2%; Average loss: 0.1216\n",
      "Iteration: 3900; Percent complete: 65.0%; Average loss: 0.1150\n",
      "Iteration: 3950; Percent complete: 65.8%; Average loss: 0.1106\n",
      "Iteration: 4000; Percent complete: 66.7%; Average loss: 0.1088\n",
      "Iteration: 4050; Percent complete: 67.5%; Average loss: 0.1041\n",
      "Iteration: 4100; Percent complete: 68.3%; Average loss: 0.1036\n",
      "Iteration: 4150; Percent complete: 69.2%; Average loss: 0.0997\n",
      "Iteration: 4200; Percent complete: 70.0%; Average loss: 0.0969\n",
      "Iteration: 4250; Percent complete: 70.8%; Average loss: 0.0931\n",
      "Iteration: 4300; Percent complete: 71.7%; Average loss: 0.0907\n",
      "Iteration: 4350; Percent complete: 72.5%; Average loss: 0.0868\n",
      "Iteration: 4400; Percent complete: 73.3%; Average loss: 0.0834\n",
      "Iteration: 4450; Percent complete: 74.2%; Average loss: 0.0837\n",
      "Iteration: 4500; Percent complete: 75.0%; Average loss: 0.0816\n",
      "Iteration: 4550; Percent complete: 75.8%; Average loss: 0.0803\n",
      "Iteration: 4600; Percent complete: 76.7%; Average loss: 0.0779\n",
      "Iteration: 4650; Percent complete: 77.5%; Average loss: 0.0776\n",
      "Iteration: 4700; Percent complete: 78.3%; Average loss: 0.0751\n",
      "Iteration: 4750; Percent complete: 79.2%; Average loss: 0.0742\n",
      "Iteration: 4800; Percent complete: 80.0%; Average loss: 0.0723\n",
      "Iteration: 4850; Percent complete: 80.8%; Average loss: 0.0701\n",
      "Iteration: 4900; Percent complete: 81.7%; Average loss: 0.0678\n",
      "Iteration: 4950; Percent complete: 82.5%; Average loss: 0.0665\n",
      "Iteration: 5000; Percent complete: 83.3%; Average loss: 0.0654\n",
      "Iteration: 5050; Percent complete: 84.2%; Average loss: 0.0645\n",
      "Iteration: 5100; Percent complete: 85.0%; Average loss: 0.0634\n",
      "Iteration: 5150; Percent complete: 85.8%; Average loss: 0.0598\n",
      "Iteration: 5200; Percent complete: 86.7%; Average loss: 0.0601\n",
      "Iteration: 5250; Percent complete: 87.5%; Average loss: 0.0589\n",
      "Iteration: 5300; Percent complete: 88.3%; Average loss: 0.0590\n",
      "Iteration: 5350; Percent complete: 89.2%; Average loss: 0.0586\n",
      "Iteration: 5400; Percent complete: 90.0%; Average loss: 0.0566\n",
      "Iteration: 5450; Percent complete: 90.8%; Average loss: 0.0539\n",
      "Iteration: 5500; Percent complete: 91.7%; Average loss: 0.0540\n",
      "Iteration: 5550; Percent complete: 92.5%; Average loss: 0.0543\n",
      "Iteration: 5600; Percent complete: 93.3%; Average loss: 0.0539\n",
      "Iteration: 5650; Percent complete: 94.2%; Average loss: 0.0529\n",
      "Iteration: 5700; Percent complete: 95.0%; Average loss: 0.0524\n",
      "Iteration: 5750; Percent complete: 95.8%; Average loss: 0.0500\n",
      "Iteration: 5800; Percent complete: 96.7%; Average loss: 0.0487\n",
      "Iteration: 5850; Percent complete: 97.5%; Average loss: 0.0471\n",
      "Iteration: 5900; Percent complete: 98.3%; Average loss: 0.0490\n",
      "Iteration: 5950; Percent complete: 99.2%; Average loss: 0.0477\n",
      "Iteration: 6000; Percent complete: 100.0%; Average loss: 0.0473\n",
      "Error: Encountered unknown word.\n",
      "Bot: \" đối_với các hội_chứng trong nhóm tế_bào tim khác là tổn_thương tại động_mạch , tim có_thể có khả_năng thay_đổi bất_thường của các nhánh động_mạch chủ ( vùng bụng ) , nhánh đêm , làm_việc nhiều , nước_tiểu sẫm , … đều rất nói máu cũng là một nguyên_nhân quan_trọng của nguyên_nhân gây bệnh . nguyên_nhân dẫn đến ngất tim , khi khối_u trong bụng tại buồng tim . – ở nữ_giới ở bụng đến khi tuổi phân , người_bệnh sẽ có các triệu_chứng như : đau bụng , chèn_ép máu , nhiễm_trùng đường tiết_niệu , mất thăng_bằng , khó tiểu , nặng ở vùng bụng , … gây ra các cơn đau ở vùng dưới da , có hiện_tượng mất nước hoặc mất nước muối sinh_lý , có_thể gây ngất lên . nếu có khối_u hoặc trong ống động_mạch , bệnh_nhân có_thể được điều_trị bằng một_số thuốc như : thuốc lợi_tiểu , … – một_số loại như : có dấu_hiệu mất máu , đặc_biệt là ở vùng tâm_đồ . siêu_âm tim là một trong những nguyên_nhân phổ_biến nhất gây ra tình_trạng này . tuy_nhiên đây là những tổn_thương mà tim từ các cơn đau trên rốn , dày , mất tập_trung , thậm_chí có_thể nhận_biết khi đi ra ngoài , khiến việc ăn_uống kém ngon_miệng , cơ_thể nghe lan rộng và có cảm_giác đau . ở vị_trí này còn kèm theo các triệu_chứng như đau bụng , ra máu , … biểu_hiện của cơn đau khi cử_động . – khi bị rối_loạn ăn_uống sọ : người bị co tay , chân , người_bệnh có_thể được đi_tiểu ra khi các chỉ_số ở ống dẫn lên não gây ở mức bình_thường , thậm_chí là mắc bệnh . do đó , khi thấy khối_u lớn hơn hoặc lớn hơn khi đau không ngon_miệng , thậm_chí là nhồi máu cơ tim hay mất nước . – các xét_nghiệm máu cũng như hạn_chế các loại quả như đau ở vùng tuổi , đặc_biệt là ở mức vừa_phải . và nhiều bệnh_lý khác như ung_thư da , ung_thư tinh_hoàn , ung_thư dạ_dày , … cũng có biểu_hiện đột_ngột ở cả hai bên , gây nên tình_trạng đau nửa đầu do khối_u đè_nén vào dây thần_kinh . đi kèm với đó là các triệu_chứng như ù tai , mất thăng_bằng , suy_giảm trí_nhớ , mất tập_trung , thậm_chí phì , ung_thư vú . do vậy , nếu được chẩn_đoán nhồi máu cơ tim , ung_thư vú , nếu bạn cảm_thấy phải khám định_kỳ tại bệnh_viện có chuyên_khoa tai mũi họng để được phát_hiện sớm và điều_trị kịp_thời . \" ở những bệnh_nhân mắc bệnh tim hoặc giảm nguy_cơ bị hội_chứng down , không có giá_trị cho người mắc các bệnh về tim_mạch . \" biểu_hiện khi bạn có giá_trị trong thời_gian này cần được sử_dụng và điều_trị hiệu_quả . đặc_biệt , một_số xét_nghiệm bao_gồm : xét_nghiệm máu để xác_định các bất_thường trong cơ_thể , phổ_biến nhất là tiểu_não – cơ_quan có độ nhạy của các\n",
      "Bot: \" vi_khuẩn hp là những cách chăm_sóc của trẻ rất dễ lấy , giúp bạn nắm về mức_độ an_toàn và đau nhức . để khắc_phục tình_trạng này , bạn cần đưa nước đến thăm khám tại bệnh_viện để được chẩn_đoán chính_xác nhất . về sau bạn uống cho trẻ là bạn cần để nghỉ_ngơi phù_hợp với mình , sau đó nghỉ_ngơi mà cần đưa trẻ đi khám . để giúp mẹ bầu có_thể biến_chứng nguy_hiểm về tình_trạng hồi_phục_sức_khỏe mình : bên cạnh đó , bác_sĩ sẽ cân_nhắc cho bạn trường_hợp chỉ_dẫn của bác_sĩ . nếu sau đó sốt cao thì bác_sĩ cũng sẽ có biện_pháp can_thiệp tốt về tình_trạng sức_khỏe của bé , giúp bạn thoải_mái hơn . nếu nhẹ ở trẻ nhỏ , bạn cần đưa nước đến lịch thăm khám để được thăm khám và điều_trị kịp_thời . \" về những chuyên_gia là bệnh nguy_hiểm , giúp bạn được thăm khám lâm_sàng và làm cho bác_sĩ thăm khám và làm các xét_nghiệm cần_thiết để có biện_pháp can_thiệp kịp_thời . \" về nhà bạn , sau đó bác_sĩ sẽ hướng_dẫn bạn đưa vào mắt sau khi hướng_dẫn bạn . nếu bạn đau thì cần thăm khám chuyên_khoa và để bác_sĩ thăm khám và đưa ra lời khuyên tốt nhất . \" về những chuyên_gia bạn mới sẽ dựa vào tình_trạng sức_khỏe của bạn . \" về những vị_trí bạn cần đưa đến cơ_sở y_tế để được thăm khám và thăm khám định_kỳ . – tái_khám theo lịch sẽ giúp lấy máu sốt và thay_đổi đau . – nếu tình_trạng này xảy ra khi thể_trạng đã dùng thuốc , bạn cần đưa trẻ đến thăm khám với bác_sĩ để được chẩn_đoán chính_xác nhất . cảm_ơn bạn đã gửi câu hỏi về chuyên_mục . do đó , để biết được tình_trạng đau nhức ống_chân của bạn còn rất nhiều hơn , bạn nên đưa trẻ đến thăm khám với bác_sĩ để được chẩn_đoán chính_xác nhất . cảm_ơn bạn đã gửi câu hỏi về chuyên_mục . do đó , để biết được tình_trạng đau nhức nên làm xét_nghiệm máu , bác_sĩ có_thể lấy máu và các biện_pháp hỗ_trợ của bác_sĩ chuyên_khoa để được tư_vấn cách điều_trị tốt nhất cho bạn . \" về sau đó bác_sĩ sẽ giúp bạn nắm rõ tình_trạng và các triệu_chứng của xương hàm , giúp bạn nắm được tình_trạng đau nhức nên đi khám để kiểm_tra tình_trạng sức_khỏe của bạn . \" với việc sốt cao , bạn cần chú_ý : – tránh xa bữa ăn hoặc đồ ăn nhiều dầu_mỡ , hoặc chưa có dấu_hiệu thuyên_giảm nên những người đang mắc các bệnh như viêm loét dạ_dày , cần được đưa để thăm khám và chẩn_đoán chính_xác nhất . trường_hợp này bạn cần thêm thông_tin về việc lấy hết mà bạn cần thăm khám với bác_sĩ để được chẩn_đoán chính_xác nhất . cảm_ơn bạn đã gửi câu hỏi về chuyên_mục . do đó , để biết được tình_trạng đau nhức\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 6000\n",
    "print_every = 50\n",
    "save_every = 1000\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# If you have cuda, configure cuda to call\n",
    "for state in encoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "for state in decoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)\n",
    "\n",
    "\n",
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0436c92297a0480712edd4992fa960a294c962643b772b3d969f22ae8272513a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
